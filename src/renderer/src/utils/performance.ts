/**
 * æ€§èƒ½ä¼˜åŒ–å·¥å…·é›†
 * æä¾›å„ç§æ€§èƒ½ä¼˜åŒ–ç›¸å…³çš„å·¥å…·å‡½æ•°å’Œç»„åˆå¼å‡½æ•°
 */

import { ref, computed, watch, nextTick, onUnmounted, type Ref } from 'vue'

/**
 * é˜²æŠ–å‡½æ•°
 */
export function debounce<T extends (...args: any[]) => any>(
  func: T,
  wait: number,
  immediate = false
): (...args: Parameters<T>) => void {
  let timeout: NodeJS.Timeout | null = null

  return function executedFunction(...args: Parameters<T>) {
    const later = () => {
      timeout = null
      if (!immediate) func(...args)
    }

    const callNow = immediate && !timeout

    if (timeout) clearTimeout(timeout)
    timeout = setTimeout(later, wait)

    if (callNow) func(...args)
  }
}

/**
 * Vueç»„åˆå¼å‡½æ•°ç‰ˆæœ¬çš„é˜²æŠ–
 * @param fn è¦é˜²æŠ–çš„å‡½æ•°
 * @param delay å»¶è¿Ÿæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
 * @returns é˜²æŠ–åçš„å‡½æ•°
 */
export function useDebounceFn<T extends (...args: any[]) => any>(
  fn: T,
  delay: number
): (...args: Parameters<T>) => void {
  return debounce(fn, delay)
}

/**
 * Vueç»„åˆå¼å‡½æ•°ç‰ˆæœ¬çš„èŠ‚æµ
 * @param fn è¦èŠ‚æµçš„å‡½æ•°
 * @param limit é™åˆ¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
 * @returns èŠ‚æµåçš„å‡½æ•°
 */
export function useThrottleFn<T extends (...args: any[]) => any>(
  fn: T,
  limit: number
): (...args: Parameters<T>) => void {
  return throttle(fn, limit)
}

/**
 * èŠ‚æµå‡½æ•°
 */
export function throttle<T extends (...args: any[]) => any>(
  func: T,
  limit: number
): (...args: Parameters<T>) => void {
  let inThrottle: boolean

  return function executedFunction(...args: Parameters<T>) {
    if (!inThrottle) {
      func(...args)
      inThrottle = true
      setTimeout(() => inThrottle = false, limit)
    }
  }
}

/**
 * è¯·æ±‚åŠ¨ç”»å¸§èŠ‚æµ
 */
export function rafThrottle<T extends (...args: any[]) => any>(
  func: T
): (...args: Parameters<T>) => void {
  let rafId: number | null = null

  return function executedFunction(...args: Parameters<T>) {
    if (rafId) return

    rafId = requestAnimationFrame(() => {
      func(...args)
      rafId = null
    })
  }
}

/**
 * ç©ºé—²æ—¶é—´æ‰§è¡Œ
 */
export function runWhenIdle<T extends (...args: any[]) => any>(
  func: T,
  timeout = 5000
): (...args: Parameters<T>) => void {
  return function executedFunction(...args: Parameters<T>) {
    if ('requestIdleCallback' in window) {
      requestIdleCallback(() => func(...args), { timeout })
    } else {
      setTimeout(() => func(...args), 0)
    }
  }
}

/**
 * æ‰¹å¤„ç†å‡½æ•°
 */
export class BatchProcessor<T> {
  private batch: T[] = []
  private timer: NodeJS.Timeout | null = null

  constructor(
    private processor: (items: T[]) => void | Promise<void>,
    private delay = 100,
    private maxBatchSize = 50
  ) { }

  add(item: T): void {
    this.batch.push(item)

    if (this.batch.length >= this.maxBatchSize) {
      this.flush()
    } else if (!this.timer) {
      this.timer = setTimeout(() => this.flush(), this.delay)
    }
  }

  flush(): void {
    if (this.timer) {
      clearTimeout(this.timer)
      this.timer = null
    }

    if (this.batch.length > 0) {
      const items = [...this.batch]
      this.batch = []
      this.processor(items)
    }
  }

  clear(): void {
    if (this.timer) {
      clearTimeout(this.timer)
      this.timer = null
    }
    this.batch = []
  }
}

/**
 * è™šæ‹Ÿæ»šåŠ¨è®¡ç®—
 */
export function useVirtualScroll<T>(
  items: Ref<T[]>,
  containerHeight: Ref<number>,
  itemHeight: number,
  buffer = 5
) {
  const scrollTop = ref(0)

  const visibleRange = computed(() => {
    const start = Math.floor(scrollTop.value / itemHeight)
    const end = Math.min(
      items.value.length - 1,
      Math.ceil((scrollTop.value + containerHeight.value) / itemHeight)
    )

    return {
      start: Math.max(0, start - buffer),
      end: Math.min(items.value.length - 1, end + buffer)
    }
  })

  const visibleItems = computed(() => {
    const { start, end } = visibleRange.value
    return items.value.slice(start, end + 1).map((item, index) => ({
      item,
      index: start + index,
      top: (start + index) * itemHeight
    }))
  })

  const totalHeight = computed(() => items.value.length * itemHeight)

  const updateScrollTop = (newScrollTop: number) => {
    scrollTop.value = newScrollTop
  }

  return {
    visibleItems,
    visibleRange,
    totalHeight,
    updateScrollTop
  }
}

/**
 * å†…å­˜æ³„æ¼æ£€æµ‹
 */
export class MemoryLeakDetector {
  private listeners: Map<string, number> = new Map()
  private timers: Set<NodeJS.Timeout> = new Set()
  private intervals: Set<NodeJS.Timeout> = new Set()
  private observers: Set<any> = new Set()

  /**
   * è®°å½•äº‹ä»¶ç›‘å¬å™¨
   */
  trackEventListener(element: EventTarget, event: string): void {
    const key = `${element.constructor.name}:${event}`
    this.listeners.set(key, (this.listeners.get(key) || 0) + 1)
  }

  /**
   * ç§»é™¤äº‹ä»¶ç›‘å¬å™¨è®°å½•
   */
  untrackEventListener(element: EventTarget, event: string): void {
    const key = `${element.constructor.name}:${event}`
    const count = this.listeners.get(key) || 0
    if (count <= 1) {
      this.listeners.delete(key)
    } else {
      this.listeners.set(key, count - 1)
    }
  }

  /**
   * è®°å½•å®šæ—¶å™¨
   */
  trackTimer(timer: NodeJS.Timeout, isInterval = false): void {
    if (isInterval) {
      this.intervals.add(timer)
    } else {
      this.timers.add(timer)
    }
  }

  /**
   * æ¸…é™¤å®šæ—¶å™¨
   */
  clearTimer(timer: NodeJS.Timeout, isInterval = false): void {
    if (isInterval) {
      clearInterval(timer)
      this.intervals.delete(timer)
    } else {
      clearTimeout(timer)
      this.timers.delete(timer)
    }
  }

  /**
   * è®°å½•è§‚å¯Ÿè€…
   */
  trackObserver(observer: any): void {
    this.observers.add(observer)
  }

  /**
   * æ–­å¼€è§‚å¯Ÿè€…
   */
  disconnectObserver(observer: any): void {
    if (observer.disconnect) {
      observer.disconnect()
    }
    this.observers.delete(observer)
  }

  /**
   * æ¸…ç†æ‰€æœ‰èµ„æº
   */
  cleanup(): void {
    // æ¸…ç†å®šæ—¶å™¨
    this.timers.forEach(timer => clearTimeout(timer))
    this.intervals.forEach(interval => clearInterval(interval))

    // æ–­å¼€è§‚å¯Ÿè€…
    this.observers.forEach(observer => {
      if (observer.disconnect) observer.disconnect()
    })

    // æ¸…ç©ºè®°å½•
    this.listeners.clear()
    this.timers.clear()
    this.intervals.clear()
    this.observers.clear()
  }

  /**
   * è·å–æ³„æ¼æŠ¥å‘Š
   */
  getLeakReport(): {
    listeners: Record<string, number>
    timers: number
    intervals: number
    observers: number
  } {
    return {
      listeners: Object.fromEntries(this.listeners),
      timers: this.timers.size,
      intervals: this.intervals.size,
      observers: this.observers.size
    }
  }
}

/**
 * æ€§èƒ½ç›‘æ§
 */
export class PerformanceMonitor {
  private marks: Map<string, number> = new Map()
  private measures: Array<{ name: string; duration: number; timestamp: number }> = []

  /**
   * å¼€å§‹æ€§èƒ½æ ‡è®°
   */
  mark(name: string): void {
    this.marks.set(name, performance.now())
  }

  /**
   * ç»“æŸæ€§èƒ½æµ‹é‡
   */
  measure(name: string, startMark?: string): number {
    const endTime = performance.now()
    const startTime = startMark ? this.marks.get(startMark) : this.marks.get(name)

    if (startTime === undefined) {
      console.warn(`Performance mark "${startMark || name}" not found`)
      return 0
    }

    const duration = endTime - startTime
    this.measures.push({
      name,
      duration,
      timestamp: endTime
    })

    return duration
  }

  /**
   * è·å–æ€§èƒ½æŠ¥å‘Š
   */
  getReport(limit = 100): Array<{ name: string; duration: number; timestamp: number }> {
    return this.measures
      .slice(-limit)
      .sort((a, b) => b.duration - a.duration)
  }

  /**
   * æ¸…ç†è®°å½•
   */
  clear(): void {
    this.marks.clear()
    this.measures = []
  }

  /**
   * è·å–å¹³å‡æ€§èƒ½
   */
  getAveragePerformance(name: string): number {
    const measures = this.measures.filter(m => m.name === name)
    if (measures.length === 0) return 0

    const total = measures.reduce((sum, m) => sum + m.duration, 0)
    return total / measures.length
  }
}

/**
 * ç»„ä»¶æ€§èƒ½åˆ†æ Hook
 */
export function usePerformanceAnalysis(componentName: string) {
  const monitor = new PerformanceMonitor()
  const leakDetector = new MemoryLeakDetector()

  // ç»„ä»¶æŒ‚è½½æ—¶å¼€å§‹ç›‘æ§
  monitor.mark(`${componentName}:mount:start`)

  const measureRender = () => {
    monitor.mark(`${componentName}:render:start`)

    return {
      end: () => monitor.measure(`${componentName}:render`, `${componentName}:render:start`)
    }
  }

  const measureUpdate = () => {
    monitor.mark(`${componentName}:update:start`)

    return {
      end: () => monitor.measure(`${componentName}:update`, `${componentName}:update:start`)
    }
  }

  // æ¸…ç†èµ„æº
  onUnmounted(() => {
    monitor.measure(`${componentName}:mount`, `${componentName}:mount:start`)
    leakDetector.cleanup()

    // è¾“å‡ºæ€§èƒ½æŠ¥å‘Š
    const report = monitor.getReport()
    if (report.length > 0) {
      console.group(`ğŸ” ${componentName} æ€§èƒ½æŠ¥å‘Š`)
      report.forEach(({ name, duration }) => {
        console.log(`${name}: ${duration.toFixed(2)}ms`)
      })
      console.groupEnd()
    }
  })

  return {
    monitor,
    leakDetector,
    measureRender,
    measureUpdate
  }
}

/**
 * æ™ºèƒ½ç¼“å­˜ Hook
 */
export function useSmartCache<T>(
  key: string,
  fetcher: () => Promise<T>,
  options: {
    ttl?: number // ç¼“å­˜æ—¶é—´ (ms)
    maxSize?: number // æœ€å¤§ç¼“å­˜å¤§å°
    staleWhileRevalidate?: boolean // ä½¿ç”¨æ—§æ•°æ®åŒæ—¶é‡æ–°éªŒè¯
  } = {}
) {
  const { ttl = 5 * 60 * 1000, maxSize = 100, staleWhileRevalidate = true } = options

  // ç®€å•çš„å†…å­˜ç¼“å­˜å®ç°
  const cache = new Map<string, { data: T; timestamp: number }>()
  const loading = ref(false)
  const data = ref<T>()
  const error = ref<Error>()

  const isExpired = (timestamp: number) => {
    return Date.now() - timestamp > ttl
  }

  const fetch = async (useCache = true) => {
    // æ£€æŸ¥ç¼“å­˜
    if (useCache && cache.has(key)) {
      const cached = cache.get(key)!

      if (!isExpired(cached.timestamp)) {
        data.value = cached.data
        return cached.data
      }

      // å¦‚æœå¯ç”¨äº† stale-while-revalidateï¼Œå…ˆè¿”å›æ—§æ•°æ®
      if (staleWhileRevalidate) {
        data.value = cached.data
      }
    }

    // è·å–æ–°æ•°æ®
    loading.value = true
    error.value = undefined

    try {
      const result = await fetcher()

      // æ›´æ–°ç¼“å­˜
      cache.set(key, { data: result, timestamp: Date.now() })

      // é™åˆ¶ç¼“å­˜å¤§å°
      if (cache.size > maxSize) {
        const firstKey: any = cache.keys().next().value
        cache.delete(firstKey)
      }

      data.value = result
      return result
    } catch (err) {
      error.value = err as Error
      throw err
    } finally {
      loading.value = false
    }
  }

  const invalidate = () => {
    cache.delete(key)
  }

  const refresh = () => fetch(false)

  return {
    data: computed(() => data.value),
    loading: computed(() => loading.value),
    error: computed(() => error.value),
    fetch,
    refresh,
    invalidate
  }
}

/**
 * å¯¼å‡ºå…¨å±€æ€§èƒ½ç›‘æ§å®ä¾‹
 */
export const globalPerformanceMonitor = new PerformanceMonitor()
export const globalMemoryLeakDetector = new MemoryLeakDetector()

/**
 * æ€§èƒ½ä¼˜åŒ–è£…é¥°å™¨
 */
export function performanceOptimized<T extends (...args: any[]) => any>(
  target: T,
  options: {
    debounce?: number
    throttle?: number
    cache?: boolean
    measure?: boolean
  } = {}
): T {
  let optimizedFn = target

  // æ·»åŠ é˜²æŠ–
  if (options.debounce) {
    optimizedFn = debounce(optimizedFn, options.debounce) as T
  }

  // æ·»åŠ èŠ‚æµ
  if (options.throttle) {
    optimizedFn = throttle(optimizedFn, options.throttle) as T
  }

  // æ·»åŠ æ€§èƒ½æµ‹é‡
  if (options.measure) {
    const originalFn = optimizedFn
    optimizedFn = ((...args: any[]) => {
      const start = performance.now()
      const result = originalFn(...args)
      const end = performance.now()

      console.log(`Function ${target.name} took ${(end - start).toFixed(2)}ms`)

      return result
    }) as T
  }

  return optimizedFn
}
